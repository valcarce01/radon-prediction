{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfed0bfc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Long Short Time Memory\n",
    "\n",
    "Table of contents\n",
    "1. [Library imports](#Library-imports)\n",
    "2. [Data Reading](#Data-reading)\n",
    "    1. [Data cleaning](#Data-cleaning)\n",
    "    2. [Data normalizarion](#Data-normalization)\n",
    "3. [LSTM](#LSTM-models-fitting)\n",
    "    1. [Fine tuning](#Fine-tuning)\n",
    "    2. [Final model](#Final-model)\n",
    "    \n",
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee1d6d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69541543",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import mix_data, generate_windows # custom functions\n",
    "import tensorflow as tf                            # LSTM\n",
    "import pandas as pd                                # DataFrames\n",
    "import numpy as np                                 # Vectorial computation\n",
    "import itertools                                   # Combinatory\n",
    "import datetime                                    # Dates formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bc5ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95760862",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/radon-data.csv')   # CSV reading\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a62170",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e904c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now we will parse the data, so it is usable\n",
    "df.time = pd.to_datetime(df['time'], unit='s', origin='unix')      # date parse\n",
    "df = df.drop(columns = [\"time\", \"id\", \"sensor_id\", \"state_time\"])  # drop useless columns\n",
    "df.state = (df.state == \"On\").astype(int)                          # binarize state\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b6997",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we now select the data from the summer (longest clean data)\n",
    "df_summer = df.iloc[36000:48000]\n",
    "df_summer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16438e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f5698",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summer_min = df_summer.min() # needed to de-normalize data\n",
    "summer_max = df_summer.max()\n",
    "\n",
    "df_summer_normalized = (df_summer - summer_min) / (summer_max - summer_min)\n",
    "df_summer_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33206110",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LSTM models fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf69ade",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will use early stopping to select the best model\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor              = 'val_loss',\n",
    "    patience             = 30,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# percentage of train samples\n",
    "train_pct = 0.9\n",
    "\n",
    "# We will store all the results in a data frame\n",
    "results = pd.DataFrame(\n",
    "    {i: [None]*15 for i in [1, 5, 10, 15, 25]}\n",
    ")\n",
    "\n",
    "cnt = 0 # helps counting\n",
    "\n",
    "for number_of_covariates in range(4):\n",
    "    for covariate_combination in itertools.combinations((\"state\", \"humidity\", \"pressure\", \"tvoc\"), \n",
    "                                                        number_of_covariates):\n",
    "        print(f\"EXECUTING OVER: {covariate_combination}\".center(100, \"*\"))\n",
    "        # We compute for each window size\n",
    "        for window_size in [1, 5, 10, 15, 25]:\n",
    "            print(\"\\n\")\n",
    "            print(f\"EXECUTING {window_size} WINDOW SIZE\".center(100), \"-\")\n",
    "            print(\"\\n\")\n",
    "            windows = {i: generate_windows(df_summer_normalized[i], window_size, 1)\n",
    "                        for i in [\"radon\"] + list(covariate_combination) }\n",
    "            \n",
    "            print(\"Windows computed, now building the model\")\n",
    "            \n",
    "            data = mix_data(windows)\n",
    "            N_total          = data.shape[0]\n",
    "            test             = data[int(train_pct * N_total):, :, :]\n",
    "            data             = data[:int(train_pct * N_total), :, :]\n",
    "            \n",
    "            model = tf.keras.models.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.InputLayer((window_size, len(windows.keys()))),\n",
    "                    tf.keras.layers.LSTM(window_size * 2),\n",
    "                    tf.keras.layers.Dense(16, activation = \"relu\"),\n",
    "                    tf.keras.layers.Dense(16, activation = \"relu\"),\n",
    "                    tf.keras.layers.Dense(1)\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            model.compile(\n",
    "                loss = tf.keras.losses.MeanSquaredError(),\n",
    "                metrics = tf.keras.metrics.RootMeanSquaredError(),\n",
    "                optimizer = tf.keras.optimizers.RMSprop()\n",
    "            )\n",
    "            \n",
    "            model.summary()\n",
    "            \n",
    "            model.fit(\n",
    "                x                = data[:, :window_size, :],\n",
    "                y                = data[:, window_size:, 0],\n",
    "                epochs           = 1_000,\n",
    "                shuffle          = False,\n",
    "                validation_split = 0.2, \n",
    "                callbacks        = [callback,],\n",
    "                verbose          = 0,\n",
    "            )\n",
    "            \n",
    "            # Model trained\n",
    "            \n",
    "            # Now compute the test predictions and add them to the data frame\n",
    "            rescale    = lambda x: x * (summer_max.radon - summer_min.radon) + summer_min.radon\n",
    "            prediction = rescale( model.predict(test[:, :window_size, :]) )\n",
    "            real       = rescale( test[:, window_size:, 0] )\n",
    "            \n",
    "            rmse_test = ( sum((prediction - real) ** 2) / len(prediction) ) ** (1/2)\n",
    "            results[window_size][cnt] = rmse_test \n",
    "            print(f\"Window {window_size}, covariates {covariate_combination}: {results[window_size][cnt]}\")\n",
    "        cnt += 1    \n",
    "        print(\"*\" * 100, \"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb46c7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fine tuning\n",
    "Once we know what model behaves the best, we try to explode this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6deae",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will use early stopping to select the best model\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor              = 'val_loss',\n",
    "    patience             = 30,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# percentage of train samples\n",
    "train_pct = 0.9\n",
    "\n",
    "# We will store all the results in a data frame\n",
    "results = pd.DataFrame(\n",
    "    {i: [None]*4 for i in [4, 8, 16, 32]}\n",
    ")\n",
    "\n",
    "# dense configurations:\n",
    "dense_combination_config = [[16], [16, 16], [32], [32, 32]]\n",
    "\n",
    "window_size = 15\n",
    "\n",
    "# we do not need to create the data in a loop:\n",
    "windows = {i: generate_windows(df_summer_normalized[i], window_size, 1)\n",
    "                for i in [\"radon\", \"state\"] }\n",
    "data    = mix_data(windows)\n",
    "N_total = data.shape[0]\n",
    "test    = data[int(train_pct * N_total):, :, :]\n",
    "data    = data[:int(train_pct * N_total), :, :]\n",
    "\n",
    "for idx, dense_config in enumerate(dense_combination_config):\n",
    "    for num_hidden_units in [4, 8, 16, 32]:\n",
    "        \n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer((window_size, len(windows.keys()))),\n",
    "                tf.keras.layers.LSTM(num_hidden_units),\n",
    "                *[tf.keras.layers.Dense(i, activation = \"relu\") for i in dense_config],\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = tf.keras.metrics.RootMeanSquaredError(),\n",
    "            optimizer = tf.keras.optimizers.RMSprop()\n",
    "        )\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.fit(\n",
    "            x                = data[:, :window_size, :],\n",
    "            y                = data[:, window_size:, 0],\n",
    "            epochs           = 1_000,\n",
    "            shuffle          = False,\n",
    "            validation_split = 0.2, \n",
    "            callbacks        = [callback,],\n",
    "            verbose          = 0,\n",
    "        )\n",
    "\n",
    "        # Model trained\n",
    "\n",
    "        # Now compute the test predictions and add them to the data frame\n",
    "        rescale    = lambda x: x * (summer_max.radon - summer_min.radon) + summer_min.radon\n",
    "        prediction = rescale( model.predict(test[:, :window_size, :]) )\n",
    "        real       = rescale( test[:, window_size:, 0] )\n",
    "\n",
    "        rmse_test = ( sum((prediction - real) ** 2) / len(prediction) ) ** (1/2)\n",
    "        results[num_hidden_units][idx] = rmse_test \n",
    "        print(f\"Config {idx} with {num_hidden_units} hidden units -> {rmse_test}\")\n",
    "        print(\"*\" * 100, \"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973a3a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babbe17",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will use early stopping to select the best model\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor              = 'val_loss',\n",
    "    patience             = 30,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# percentage of train samples\n",
    "train_pct = 0.9\n",
    "\n",
    "window_size = 15\n",
    "\n",
    "# we do not need to create the data in a loop:\n",
    "windows = {i: generate_windows(df_summer_normalized[i], window_size, 1)\n",
    "                for i in [\"radon\", \"state\"] }\n",
    "data    = mix_data(windows)\n",
    "N_total = data.shape[0]\n",
    "test    = data[int(train_pct * N_total):, :, :]\n",
    "data    = data[:int(train_pct * N_total), :, :]\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer((window_size, len(windows.keys()))),\n",
    "        tf.keras.layers.LSTM(15),\n",
    "        tf.keras.layers.Dense(32, activation = \"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    metrics = tf.keras.metrics.RootMeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x                = data[:, :window_size, :],\n",
    "    y                = data[:, window_size:, 0],\n",
    "    epochs           = 1_000,\n",
    "    shuffle          = False,\n",
    "    validation_split = 0.2, \n",
    "    callbacks        = [callback,],\n",
    ")\n",
    "\n",
    "# Model trained\n",
    "\n",
    "# Now compute the test predictions and add them to the data frame\n",
    "rescale    = lambda x: x * (summer_max.radon - summer_min.radon) + summer_min.radon\n",
    "prediction = rescale( model.predict(test[:, :window_size, :]) )\n",
    "real       = rescale( test[:, window_size:, 0] )\n",
    "\n",
    "rmse_test = ( sum((prediction - real) ** 2) / len(prediction) ) ** (1/2)\n",
    "print(f\"RMSE -> {rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f092cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"../output/radon.h5\", save_format = \"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b19b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"../output/radon.pb\", save_format = \"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd9346",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summer_min, summer_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5686ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"predictions\": prediction.flatten(),\n",
    "        \"real\": real.flatten(),\n",
    "    }\n",
    ").to_csv(\"../data/predictions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}